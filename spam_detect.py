# -*- coding: utf-8 -*-
"""spam_detect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/Razia-Amy/12fef51df9cd785964a4871a4f19fae1/spam_detect.ipynb
"""

# Description: This program detects if an email spam (1) or not .(0).

# Import libraries
import numpy as np
import pandas as pd
import nltk
from nltk.corpus import stopwords
import string

#Load the data
from google.colab import files
uploaded = files.upload()

#Read the CSV file
df = pd.read_csv('emails.csv')

#Print the first 5 rows of data
df.head(5)

#Print the shape(Get the number of rows and columns)
df.shape

#Get the columns name
df.columns

#Check for duplicated and remove them
df.drop_duplicates(inplace = True)

#Show the new shape(number of row and columns)
df.shape

#Show the number of missing(NAN, NaN, na) data for each column
df.isnull().sum()

#Download the stopwords package
nltk.download('stopwords')

def process_text(text):

  #1 remove punctuation
  #2 remove stopwords
  #3 return a list of clean text words

  #1
  nopunc = [char for char in text if char not in string.punctuation]
  nopunc = ''.join(nopunc)

  #2
  clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]

  #3
  return clean_words

#Show the tokenization(a list of token also called lemmas)
df['text'].head().apply(process_text)

#Examples

message4 = 'hello world hello world'
message5 = 'test test test test one'
print(message4)
print()

#Convert the text to a matrix of token counts
from sklearn.feature_extraction.text import CountVectorizer
bow4 = CountVectorizer(analyzer=process_text).fit_transform([[message4], [message5]] )
print(bow4)

print(bow4.shape)

#Convert a collection of text to a matriz of tokens
from sklearn.feature_extraction.text import CountVectorizer
messages_bow = CountVectorizer(analyzer=process_text).fit_transform(df['text'])

#Split the data into 80% training and 20% testing
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['spam'], test_size=0.20, random_state=0)

#Get the shape of messages_bow
messages_bow.shape

#Create and train the Naive Bayes Classifier
from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB().fit(X_train, y_train)

#Print the predictions
print(classifier.predict(X_train))

#Print the actual values
print(y_train.values)

#Evaluate the model on the training data set
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(X_train)
print(classification_report(y_train, pred))
print()
print('Confusion Matrix: \n', confusion_matrix(y_train, pred))
print()
print('Accuracy: ', accuracy_score(y_train, pred))

#Print the predictions
print(classifier.predict(X_test))

#Print the actual values
print(y_test.values)

#Evaluate the model on the training data set
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
pred = classifier.predict(X_test)
print(classification_report(y_test, pred))
print()
print('Confusion Matrix: \n', confusion_matrix(y_test, pred))
print()
print('Accuracy: ', accuracy_score(y_test, pred))